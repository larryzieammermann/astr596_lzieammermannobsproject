{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>OBSERVATIONAL ASTROPHYSICS â€“ FALL 2019 Reduction Exercise: Part 1</h2>\n",
    "\n",
    "In this exercise you will go through and view all of your data to check for any issues.  You will also access the logs and you will each make your own lists of all the data that fits into a set of categories.\n",
    "\n",
    "copy over \n",
    "\n",
    "<h4> Copy over the images from a public shared drive to <i>your</i> departmental shared disk space </h4>\n",
    "\n",
    "You will reduce the data only for your observation night.  The department has created space for each of you on its network drive space.  You will store all of your data there so that you can work from any computer.\n",
    "\n",
    "Text in quotes <> indicates a placeholder value that you will need to fill in.  For example < your night> could be 20191104.  Substitute only uout name here.  Don't include a space at the beginning as I just had to put that in to get it to display properly.\n",
    "\n",
    "The raw data are all stored in the ~/RFSLAB/USER_DPT/_PUBLIC/ASTR596/Data/Raw/< your night>\n",
    "\n",
    "Your personal network drive space is at ~/RFSLAB/USER_DPT/< KUID>\n",
    "\n",
    "To copy over the data from the public directory to your directory go to your network directory in the command line and:\n",
    "\n",
    "1. make a directory tree called \"ASTR596/Data/Raw\" and cd into that directory\n",
    "\n",
    "2. from within that directory type (without the quotes <i>rsync -u -a -v ~/RFSLAB/USER_DPT/_PUBLIC/ASTR596/Data/Raw/< your_night> .</i>, where there is a space before the final \".\"\n",
    "\n",
    "3. Make directories in your personal space called ~/RFSLAB/USER_DPT/< KUID>/ASTR596/Data/Reduced/< your_night> and ~/RFSLAB/USER_DPT/< KUID>/ASTR596/Data/Files \n",
    "\n",
    "4. You will need to make lists that contain the different kinds of images.  Open the log file on google docs for your night.  \n",
    "\n",
    "\n",
    "Everywhere with a \\***** you will need to change the code\n",
    "\n",
    "<h4>What to hand in</h4>\n",
    "You should make a copy of this notebook to your own directory and add that to your own repository.\n",
    "\n",
    "You will hand in this completed notebook that includes all of your overscan check plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy import units as u\n",
    "\n",
    "# this is a list of all the bias image names\n",
    "#********************\n",
    "biaslist = np.array([\"b000.fits\",\"b001.fits\",\"b002.fits\",\"b003.fits\",\"b004.fits\",\"b005.fits\",\"b006.fits\",\"b007.fits\",\"b008.fits\",\"b009.fits\",\"b010.fits\",\"b011.fits\",\"b012.fits\",\"b013.fits\",\"b014.fits\",\"b015.fits\",\"b016.fits\",\"b017.fits\",\"b018.fits\",\"b019.fits\",\"b020.fits\",\"b021.fits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Repeat for the twilight flat frames in each filter using a list called \"flatlist_< filtname>\", where filname shoudl be B, V, or R .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a list of all the flatfield images.  There may need to be more than one list\n",
    "#*************\n",
    "flatlist_B = np.array([\"f026.fits\", \"f027.fits\",\"f028.fits\",\"f029.fits\",\"f030.fits\"])\n",
    "flatlist_V = np.array([\"f031.fits\", \"f032.fits\",\"f033.fits\",\"f034.fits\",\"f035.fits\"])\n",
    "flatlist_R = np.array([\"f036.fits\", \"f037.fits\",\"f038.fits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Repeat for the science frames, where this should only include the frames that you are using for science on your clusters.  Do **not** include focus, pointing, or test frames.  These should be called, e.g. \"sciencelist_< filtname>_< cluster name>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a list of all the science images.  There may need to be more than one list\n",
    "#*************\n",
    "sciencelist_R_Nova = np.array([\"s049.fits\", \"s050.fits\",\"s051.fits\",\"s052.fits\"])\n",
    "sciencelist_V_Nova = np.array([\"s053.fits\", \"s054.fits\",\"s055.fits\"])\n",
    "sciencelist_B_Nova = np.array([\"s056.fits\", \"s057.fits\",\"s058.fits\"])\n",
    "sciencelist_B_NGC7128 = np.array([\"s064.fits\", \"s065.fits\", \"s066.fits\", \"s067.fits\", \"s0648.fits\", \"s069.fits\", \"s070.fits\", \"s071.fits\", \"s072.fits\", \"s073.fits\", \"s074.fits\"])\n",
    "sciencelist_V_NGC7128 = np.array([\"s078.fits\", \"s079.fits\", \"s080.fits\", \"s081.fits\", \"s082.fits\", \"s083.fits\", \"s084.fits\", \"s085.fits\", \"s086.fits\", \"s087.fits\", \"s088.fits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. open ds9 and one after the other display the images in the lists above, which is fewer than the actual number of images you took in a night, and examine them to make sure that there is nothing wrong with them, e.g. satellite trails, very elongated stars.  Make a list that contains any bad images there.  *Ask me if you are unsure what a bad image is.*\n",
    "\n",
    "Then use the code below to trim the bad images from each of your lists.\n",
    "\n",
    "You will need to execute the routine in the immediately following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that takes an array of image names and an array of bad images and \n",
    "#returns a list of images that were not in the bad list\n",
    "def imlist_clean(imlist, badlist):\n",
    "\n",
    "    #updated versions of your image list that excludes these bad images\n",
    "    #this intializes it\n",
    "    goodimlist = np.array([]) \n",
    "\n",
    "    #this loops through every element in badlist\n",
    "    for i in range(len(imlist)): \n",
    "    \n",
    "        #see if that element of imlist exists in the list of bad images.\n",
    "        #ibad is an array of indices of the array badlist that match the element of imlist\n",
    "        ibad = np.where(badlist == imlist[i]) \n",
    "\n",
    "        #this is just to reformat ibad, which is output by where as a 2D array, where the \n",
    "        #first element is the one we want\n",
    "        ibad = ibad[0]  \n",
    "\n",
    "        #this tests if there was a match with badlist.  If there was not, then append\n",
    "        #the good image names to the good image list\n",
    "        if ibad.size==0: \n",
    "            goodimlist = np.append(goodimlist,imlist[i]) \n",
    "\n",
    "    #return something from the routine\n",
    "    return(goodimlist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is where you remove the bad images from your list.  If there are no bad images, you should make the badlist be an empty array but you still need to run the imlist_clean() routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biaslist_good =  ['b000.fits' 'b001.fits' 'b002.fits' 'b003.fits' 'b004.fits' 'b005.fits'\n",
      " 'b006.fits' 'b007.fits' 'b009.fits' 'b010.fits' 'b012.fits' 'b013.fits'\n",
      " 'b014.fits' 'b015.fits' 'b016.fits' 'b017.fits' 'b018.fits' 'b020.fits']\n",
      "flatlist_B_good =  ['f026.fits' 'f027.fits' 'f028.fits' 'f029.fits' 'f030.fits']\n",
      "flatlist_V_good =  ['f031.fits' 'f032.fits' 'f033.fits' 'f034.fits' 'f035.fits']\n",
      "flatlist_R_good =  ['f036.fits' 'f037.fits' 'f038.fits']\n",
      "sciencelist_R_Nova_good =  ['s049.fits' 's050.fits' 's051.fits' 's052.fits']\n",
      "sciencelist_V_Nova_good =  ['s053.fits' 's054.fits' 's055.fits']\n",
      "sciencelist_B_Nova_good =  ['s056.fits' 's057.fits' 's058.fits']\n",
      "sciencelist_B_NGC7128_good =  ['s064.fits' 's065.fits' 's066.fits' 's067.fits' 's0648.fits' 's069.fits'\n",
      " 's070.fits' 's071.fits' 's072.fits' 's073.fits' 's074.fits']\n",
      "sciencelist_V_NGC7128_good =  ['s078.fits' 's079.fits' 's080.fits' 's081.fits' 's082.fits' 's083.fits'\n",
      " 's084.fits' 's085.fits' 's086.fits' 's087.fits' 's088.fits']\n"
     ]
    }
   ],
   "source": [
    "#a list of bad images\n",
    "#*************\n",
    "badlist = np.array([\"b008.fits\",\"b011.fits\",\"b019.fits\",\"b021.fits\",\"f024.fits\",\"b025.fits\"])\n",
    "\n",
    "#make a cleaned version of the biaslist\n",
    "biaslist_good = imlist_clean(biaslist,badlist)\n",
    "print(\"biaslist_good = \",biaslist_good)\n",
    "flatlist_B_good = imlist_clean(flatlist_B,badlist)\n",
    "print(\"flatlist_B_good = \",flatlist_B_good)\n",
    "flatlist_V_good = imlist_clean(flatlist_V,badlist)\n",
    "print(\"flatlist_V_good = \",flatlist_V_good)\n",
    "flatlist_R_good = imlist_clean(flatlist_R,badlist)\n",
    "print(\"flatlist_R_good = \",flatlist_R_good)\n",
    "sciencelist_R_Nova_good = imlist_clean(sciencelist_R_Nova,badlist)\n",
    "print(\"sciencelist_R_Nova_good = \",sciencelist_R_Nova_good)\n",
    "sciencelist_V_Nova_good = imlist_clean(sciencelist_V_Nova,badlist)\n",
    "print(\"sciencelist_V_Nova_good = \",sciencelist_V_Nova_good)\n",
    "sciencelist_B_Nova_good = imlist_clean(sciencelist_B_Nova,badlist)\n",
    "print(\"sciencelist_B_Nova_good = \",sciencelist_B_Nova_good)\n",
    "sciencelist_B_NGC7128_good = imlist_clean(sciencelist_B_NGC7128,badlist)\n",
    "print(\"sciencelist_B_NGC7128_good = \",sciencelist_B_NGC7128_good)\n",
    "sciencelist_V_NGC7128_good = imlist_clean(sciencelist_V_NGC7128,badlist)\n",
    "print(\"sciencelist_V_NGC7128_good = \",sciencelist_V_NGC7128_good)\n",
    "#Now repeat this block of code for the twilight flats and the science flats in each band\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Trim the overscan from every image </h4>\n",
    "\n",
    "We will be using the \"ccdproc\" package in python, which has a built in \"CCDData\" object.\n",
    "\n",
    "You will read in every image and run a ccdproc command that takes the median of each row of the overscan region and fits a polynomial to these median values over all rows.  This polynomial will then be subtracted from each row of the image.  It will then write out the image.\n",
    "\n",
    "Before you do this, you will create an image that contains the uncertainty of every pixel based on the Poisson counts and the readnoise.\n",
    "\n",
    "Make a directory in which all your reduced images will be saved.  This should be \n",
    "\n",
    "In running the overscan subtraction you will need to tell the code what rows and columns to use.  In specifying this, assume: 1) that the array is square; 2) that python arrays start with zero while FITS images start with one; 3) that python arrays index rows as the first element and columns as the second.  So accessing the 9th and 10th column of an image is done by im[:,8:9]\n",
    "\n",
    "The readme docs that describe this process are given at: https://ccdproc.readthedocs.io/en/latest/reduction_toolbox.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.nddata import CCDData\n",
    "import ccdproc\n",
    "from astropy.modeling import models\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#A function that subtracts the overscan region from a list of images.  \n",
    "def oscan_subtract(imlist, redpath, rawpath):\n",
    "    #Parameters are imlist = an array of image names\n",
    "    #redpath = the path where the reduced images will be written\n",
    "    #rawpath = the path where the raw images are located\n",
    "\n",
    "    #*************\n",
    "    #Look in the telescope manual on google drive for the gain and readnoise values\n",
    "    g = 2.13 #gain in units of electrons/ADU\n",
    "    rn = 3.88 #readnoise in electrons\n",
    "\n",
    "    #loop over every image name in the bias list\n",
    "    for imname in biaslist_good:\n",
    "    \n",
    "        #create the image name, including the path\n",
    "        imstr = rawpath + imname\n",
    "        #read that into a CCDData object.  This allows you to specify a unit\n",
    "        im = CCDData.read(imstr,unit = \"adu\")\n",
    "\n",
    "        #in computing the noise you need to convert the image from ADU into electrons\n",
    "        #the uncertainty of a pixel is u=sqrt(g*p + sigma_RN**2), where g is the gain\n",
    "        #p is the pixel count in ADU and sigma_RN is the readnoise\n",
    "        #the u.<blah> is a python way of specifying unit that goes along with the number\n",
    "\n",
    "        im_with_err = ccdproc.create_deviation(im,gain=g * u.electron/u.adu, readnoise=rn*u.electron)\n",
    "    \n",
    "        #gain correct the images\n",
    "        gain_corr_im = ccdproc.gain_correct(im_with_err,g * u.electron/u.adu)\n",
    "    \n",
    "        #overscan correction\n",
    "        #specify the order of the polynomial that you will use.  start with a polynomial \n",
    "        #of one term (constant) and see how well it does\n",
    "        #**********\n",
    "        poly_model = models.Polynomial1D(1)\n",
    "        oscan_sub_im = ccdproc.subtract_overscan(gain_corr_im,overscan = gain_corr_im[2048:], \\\n",
    "                                                 overscan_axis=1,model=poly_model)\n",
    "    \n",
    "        #make a plot of the median of each row of the now-subtracted overscan columns\n",
    "        #to make sure that they are centered around zero\n",
    "        #first make an array of zeros that is the same number of rows of the image\n",
    "        oscan_check = np.zeros(len(np.asarray(oscan_sub_im[:])) )\n",
    "        #now fill in an array with the row number\n",
    "        oscan_check_nrow = np.arange(len(np.asarray(oscan_sub_im[:])) )\n",
    "        #now go through every row, take the median, and put it into the check array\n",
    "        #**********\n",
    "        for i in range(len(np.asarray(oscan_sub_im[:]))): \n",
    "            oscan_check[i] = np.median(oscan_check[i, 2048:])\n",
    "    \n",
    "            \n",
    "        #make a plot of the median vs the row number\n",
    "        #**********\n",
    "        plt.plot(oscan_check[i],i,'bo')\n",
    "        plt.show()\n",
    "        \n",
    "        #trim off the overscan regions\n",
    "        #**********\n",
    "        trimmed_im = ccdproc.trim_image(oscan_sub_im[2048:])\n",
    "        \n",
    "        #write the image\n",
    "        tr_imname = imname.replace('.fits','_tr.fits',1)\n",
    "        tr_imnamestr = redpath + tr_imname\n",
    "        trimmed_im.write(tr_imnamestr,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Negative values in array will be replaced with nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2048,2200) (0,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-b03a6406e5a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mredpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/l943z843/RFSLAB/USER_DPT/l943z843/ASTR596/Data/Reduced/20191106/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moscan_subtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiaslist_good\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-207-0f506be5e0df>\u001b[0m in \u001b[0;36moscan_subtract\u001b[0;34m(imlist, redpath, rawpath)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mpoly_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPolynomial1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         oscan_sub_im = ccdproc.subtract_overscan(gain_corr_im,overscan = gain_corr_im[2048:], \\\n\u001b[0;32m---> 41\u001b[0;31m                                                  overscan_axis=1,model=poly_model)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#make a plot of the median of each row of the now-subtracted overscan columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3env/lib/python3.7/site-packages/ccdproc/log_meta.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwd)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Grab the logging keyword, if it is present.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mlog_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LOG_ARGUMENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlog_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3env/lib/python3.7/site-packages/ccdproc/core.py\u001b[0m in \u001b[0;36msubtract_overscan\u001b[0;34m(ccd, overscan, overscan_axis, fits_section, median, model)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;31m# subtract the overscan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     \u001b[0msubtracted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mccd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moscan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msubtracted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2048,2200) (0,1) "
     ]
    }
   ],
   "source": [
    "#perform overscan subtraction on the bias frames\n",
    "#the reduction path\n",
    "#****** This should be the absolute path to your files\n",
    "rawpath = \"/home/l943z843/ASTR596/Data/Raw/20191106/\"\n",
    "redpath = \"/home/l943z843/RFSLAB/USER_DPT/l943z843/ASTR596/Data/Reduced/20191106/\"\n",
    "\n",
    "oscan_subtract(biaslist_good, redpath, rawpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have run your code with no bugs, you should check that 1) the plots look like you've done the correct overscan subtraction, 2) you have the right polynomial order, 3) by checking in ds9 that you have trimmed the images correctly.  Step #3 likely only needs to be done for a couple of images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
